# Appendix: Reference Distributions {#dist}
In this chapter I discuss a handful of reference distributions that you may encounter while working thorugh this course. I don't go into great detail on any of these distributions (or their mathematical structure) because smarter, better, and more authoritative descriptions can be found elsehwere in reference texts or online. This is the $1 tour.  

```{r dist1, include=FALSE}
library(tidyverse)
library(gridExtra)
library(grid)
knitr::opts_chunk$set(echo = TRUE)
```

## Uniform Distribution {#unif_dist}
The uniform distribution describes a situation where all obervations have an equal probability of occurrence. Examples of uniform distributions include: the outcome of a single  roll of a 6-sided die, or the flip of a coin, or the chance of picking a spade, heart, diamond, or club from a well-shuffled deck of cards.  In each of these cases, all potential outcomes have an equal chance of occuring.  A uniform distribition may be specified simply by setting the range of possible outcomes (i.e., a minimum, maximum, and anything in between). The "in-between" part also lets you specify whether you want to allow outcome values that are continuous (like from a random-number generator), integers (like from a dice roll), or some other format (like a binary 0 or 1; heads or tails).  

Below, we create a [probability density function](#pdf)  for the first roll of a six-sided die; this is a *discrete uniform distribition* since we only allow integers to occur.  A uniform distribution is appropriate here because any of the numbers between 1 and 6 has equal probability of being rolled.  Notice the shape of the histogram...flat.

``` {r unif_dist, warning=FALSE}
#create a uniform distribition for the first roll of a 6-sided die
six_sided <- ceiling(runif(10e4, min=0, max=6))

#create a histogram of the probability density for a uniform distribution 
hist(six_sided, 
      breaks = c(0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5), 
      freq = FALSE,
      xlab = "Number",
      ylab = "Probability",
      main = "Outcome probability for the first roll of a 6-sided die")
```
  
  
### Characteristic Plots: Uniform Distribution
Below, we show the cumulative distribition plot and probability density function for a uniform distribution between 0 and 1.
``` {r unif_dist_plots2, echo=FALSE}
unif_dist2<-tibble(data = seq(0,1,0.001), 
                  quant = seq(0,1,0.001))
                  

unif_cdf <- ggplot(data = unif_dist2) +
  geom_point(aes(x=quant, y = data)) +
  labs(title = "Uniform Cumulative Distribution",
       y ="Cumlative Fraction",
       x = "Values")

unif_hist <- ggplot(data = unif_dist2) +
  stat_density(aes(x = data),
                 outline.type = "full",
               kernel = "gaussian",
               n = 4096,
               alpha = 0.75,
               bw = .001) +
  labs(title = "Uniform Probability Density",
       y = "Probability",
       x = "Values")

grid.arrange(unif_cdf, unif_hist, ncol=2)

```

## Normal Distribution {#normal_dist}
The normal distribution arises from phenomena that tend to have *additive* variability. By "additive", I mean that the outcome (or variable of interest) tends to vary in a +/- fashion from one obervation to the next. Lots of things have additive variability: the heights of 1^st^ graders, the size of pollen grains from a tree or plant, the variation in blood pressure across the population, or the average temperature in Fort Collins, CO for the month of June.  

Let's examine what *additive variability* looks like using the 6-sided dice mentioned above.  Although a dice roll has a uniform distribution of possible outcomes (rolling a 1,2,3,4,5, or 6), the variability associated with adding up the sum of three or more dice creates a normal distribition of outcomes.  If we were to roll four, 6-sided dice and sum the result (getting a value between 4 and 24 for each roll), and then repeat this experiment 10,000 times, we see the distribution shown below.  The smooth line represents a fit using a normal distribution - a pretty nice fit considering that we are working with a discrete (integer-based) dataset!
``` {r normal1, warning=FALSE, echo=FALSE}
#sample a uniform distribution between 0 and 6, replicate 1000 times
#use 'ceiling' function to round up results
four_dice <- tibble(sum = replicate(10000, runif(4, min=0, max=6) %>% 
                         ceiling() %>% 
                         sum() #sum the result
                       ))
plot_normal1 <- ggplot(data = four_dice)+
  geom_histogram(aes(x = sum, after_stat(density)),
                 bins = 21,
                 fill = "navy") + 
  stat_function(fun = dnorm, n = 101, 
                args = list(
                  mean = mean(four_dice$sum), 
                  sd = sd(four_dice$sum)
                  )
                ) +
  theme_bw()
plot_normal1
```

### Normal Distribution: Characteristic Plots

Unlike the uniform distribution, the normal distribution is not specified by a range (it doesn't have one).  The normal distribution is specified by a *central tendancy* (a most-common value) and a measure of data's *dispersion* or spread (a standard deviation). A normal distribution is symmetric, meaning that the spread of the data is equal on each side of the central tendency.  This symmetry also means that the mode (the most common value), the median (the 50^th^ percentile or 0.5 quantile) and the mean (the average value) are all equal. A series of normal distributions of varying dispersion is shown in the panels below.

``` {r normal2, warning=FALSE, echo=FALSE, fig.width=6, fig.height=4}
norm2 <- tibble(a = rnorm(n = 20000, mean = 50, sd = 5),
                b = rnorm(n = 20000, mean = 50, sd = 10),
                c = rnorm(n = 20000, mean = 50, sd = 15),
                d = rnorm(n = 20000, mean = 50, sd = 20),
                e = rnorm(n = 20000, mean = 50, sd = 25))

ggplot(data = norm2) +
  stat_ecdf(aes(x = a, color = "sd = 5")) +
  stat_ecdf(aes(x = b, color = "sd = 10")) +
  stat_ecdf(aes(x = c, color = "sd = 15")) +
  stat_ecdf(aes(x = d, color = "sd = 20")) +
  stat_ecdf(aes(x = e, color = "sd = 25")) +
  xlim(0,100) +
  labs(title = "\"Normal\" Cumulative Distribution",
       x = "Values",
       y = "Cumulative Fraction") +
  scale_color_manual(values = c("black", "blue", "orange", "magenta", "darkgreen"), 
                     breaks=c("sd = 5","sd = 10","sd = 15", "sd = 20", "sd = 25"),
                     name = "Mean = 50") +
  theme_bw()

ggplot(data = norm2) +
  geom_density(aes(x = a, color = "sd = 5"),
               adjust = 2) +
  geom_density(aes(b, color = "sd = 10"),
               adjust = 2) +
  geom_density(aes(c, color = "sd = 15"),
               adjust = 2) +
  geom_density(aes(d, color = "sd = 20"),
               adjust = 2) +
  geom_density(aes(e, color = "sd = 25"),
               adjust = 2) +
  xlim(0,100) +
  labs(title = "\"Normal\" Probability Density",
       x = "Values",
       y = "Probability") +
  scale_color_manual(values = c("black", "blue", "orange", "magenta", "darkgreen"), 
                     breaks=c("sd = 5","sd = 10","sd = 15", "sd = 20", "sd = 25"),
                     name = "Mean = 50") +
  theme_bw() 


```

## Log-normal Distribution
Multiplicative variation is what gives rise to a "log-normal" distribution: a special type of skewed data.  

Let's create two normal distributions for variables 'a' and 'b':  

``` {r a_b_normal_dist, warning=FALSE}
#create two variables that are normally distributed
normal_data <- tibble(a = rnorm(n=1000, mean = 15, sd = 5),
                   b = rnorm(n=1000, mean = 10, sd = 3))
```

Individually, we know that these data are normally distributed (because we created them that way), but what does the distribution look like if we add these two variables together?

``` {r a_b_histogram, warning=FALSE}
#add those variables together and you get a normal distribution
normal_data %>% mutate(c = a + b) -> normal_data

ggplot2::ggplot(data = normal_data) + 
  geom_histogram(aes(c),
                 bins = 30,
                 fill = "white",
                 color = "darkgrey") +
  theme_minimal() +
  theme(text = element_text(size=20))
ggsave("./images/hist_a_b.png", dpi = 150)
```
Answer: still normal.  Since all we did here was add together two normal distributions, we simply created a third (normal) distribution with more additive variability.  

What happens, however, if we multiply together a series of normally distributed variables?  
``` {r a_b_lognormal, warning=FALSE}
#multiply together three normal variables
normal_data %>% 
  mutate(d = sample(a*b*c, 1000)) -> log_data

ggplot2::ggplot(data = log_data) + 
  geom_histogram(aes(d),
                 bins = 30,
                 fill = "white",
                 color = "darkgrey") +
  theme_minimal() +
  theme(text = element_text(size=20))
ggsave("./images/hist_skew_out.png", dpi = 150)
```

``` {r a_b_lognormal_log_axis, warning=FALSE}
#plot the same data on a log scale (x axis)

ggplot2::ggplot(data = log_data) + 
  geom_histogram(aes(d),
                 bins = 25,
                 fill = "white",
                 color = "darkgrey") +
  theme_minimal() +
  scale_x_log10() +
  theme(text = element_text(size=20))
ggsave("./images/hist_skew_out_logx.png", dpi = 150)
```


