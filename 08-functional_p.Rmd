# Functional Programming {#rprog4}


```{r rprog3-1, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = 'center')
library(tidyverse)
library(lubridate)    # for working with date-times
library(knitr)
library(bookdown)
library(scales)
```

## Ch. 8 Objectives

This chapter is designed around the following learning objectives for functional
programming in R. Upon completing this chapter, you should be able to:  

- Describe the basic tenets of functional programming
- Define functions and their basic attributes
- Create simple functions using named and optional arguments
- Define the meaning of *"vectorized operations"* in R
- Interpret and apply the `purrr::map` family of functions

## What is ***functional programming***?

*Functional programming* means just that: programming with functions. A basic 
philosophy of functional programming in R is to replace "for-loops" with functions.
While there isn't anything inherently wrong with for-loops, they can be difficult
to follow, especially when they are nested within one to another.
R is well-poised to support the elimination of "for-loops" because R is a 
*vectorized language*. To be vectorized means that you don't need a for-loop to 
execute this code:

``` {r vectorized-code, eval=FALSE}
evens <- seq(from = 2, to = 20, by = 2)  
evens_squared <- evens^2
```

with code like this:

```{r for-loop-code, eval=FALSE}
evens_squared <- for( i in length(evens)){  
  evens_squared <- evens[i] * evens[i] 
}

```

The top code performs the `squared` operator across each entry in the 
vector, one after another.  The bottom set uses a for-loop to accomplish the
same task, albeit in a longer (and harder to follow) version.

The pipe operator `%>%` is an ally in this endeavor because it allows you to 
pass an object through series of functions onto a vector (or data frame) in 
serial order. The pipe function is also easier to follow (with your mind) because 
it allows you to interpret the code as if you were reading instructions in a 
"how-to" manual: 
*"take this object, then do this, then do this, then do that"*. Without the `%>%`
operator, we are forced to nest functions together or write long and verbose
code that steps through treatments slowly (and somewhat painfully).  Looking at
the code below should make clear which set is easier to comprehend:

``` {r nested-or-piped, eval=FALSE}

#nested code
daily_show_2000 <- select(filter(rename(daily_show, 
                                          year = YEAR, 
                                          job = GoogleKnowlege_Occupation, 
                                          date = Show, 
                                          name = Raw_Guest_List), 
                                   year == 2000), 
                            job, date, name)
#piped code
daily_show_2000 <- daily_show %>%
  rename(year = YEAR, 
         job = GoogleKnowlege_Occupation, 
         date = Show, 
         name = Raw_Guest_List) %>%
  filter(year == 2000) %>%
  select(job, date, name)
  
  
```

In the nested example above, we "see" the `dplyr::select()` function first, yet 
yet the arguments to this function show up last (ar the end of the nested code).
This separation between functions and their arguments only gets worse as the 
degree of nesting increases. The piped code, however, produces the same result
as the nested code but in a much more "readable" fashion. A similar analogy 
holds for the nesting of "for-loops" (which, when nested, are even 
harder to follow!).

## Writng Functions

> <span style="color: blue;"> "If you have to do something more than twice,
write a function to do it." - Programming Proverb </span>

Up to this point, we have relied entirely on functions sourced from base R or
from packages like `Tidyverse;:`(and for good reason - they are terribly useful).  
Every programmer, howver, at some point in their journey, discovers that the 
function they are desiring simply doesn't exist - at least not in the way that 
suits their vision. To that end, its worth learning how to create your own 
functions.

The syntax for function generation is relatively straight forward:

``` {r function-gen, eval=FALSE}
#example code; will not run

function_name <- function(argument1, argument2, ...) {
   # insert code to manipulate arguments here
   # maybe some code to check validity of input arguments
   # specify a return value, if desired
}
```

Each function has **arguments** as input, **body code** as the working parts, and
an **environment** where the function resides. These components can be
accessed by passing the function name as an argument to:  

- `formals()`, to see arguments
- `body()`, to see the function's code
  - or type just the function name, without `()`, into the console
  - *but note that many base R functions are coded in C* and can be accessed 
  [on GitHub](https://github.com/wch/r-source){target="_blank"}. 
- `environment()`, to see where the function resides.
  - more on *R environments* below

### Example Function: my_mean
Let's create a simple function, named `my_mean`, to calculate the arithmetic mean 
for a numeric vector. This function takes only one argument, a vector `x`, for 
which we calculate the mean (`sum(x) / length(x)`), assign it to a
value `y`, and the return `y` as output. Note that all the *"action"* for `my_mean`
happens within the curly braces `{ }` that follow the function assignment. 

``` {r my-mean}
my_mean <- function(x) {
     y <- sum(x) / length(x) # calculate mean(x) if true
     return(y)
   }

my_mean(1:5)
```

While this function is simple and straightforward, it does have some limitations.
For example, what happens if we pass a character vector to `my_mean` or a numeric
vector that contains `NA` values?  In the former case, we will get an error
because our function uses the base R function `sum()`, which requires numeric, 
logical, or complex vectors as inpout (so our function inherits the properties
of that function).

If any `NA` values are present, however, we are less fortunate: only NA is 
returned.  This many not seem like a big deal but if your analyss depends on
calling `my_mean` in several locations (over and over), you might have a hard 
time debugging it...

``` {r my-mean-NA}

my_mean(c(1, 2, 3, 4, 5, NA))

```

For this reason, functions often contain *optional arguments* that allow the user
to specify how to handle such errors.  The function `my_mean2` below contains
an optional argument, `na.rm = TRUE`, that defaults to remove `NA` values when 
present.  This function uses `if else` logic to handle the `na.rm = TRUE` 
argument, since this argument can only have one of two values.

``` {r my-mean2}

my_mean2 <- function(x, na.rm = TRUE) {
  if (na.rm == FALSE) {
    y <- sum(x) / length(x)
    return(y)
    }
  else {
    y <- sum(na.omit(x)) / length(na.omit(x))
    return(y)
    }
}
```
Now, when we pass a vector containing `NAs` to `my_mean2`, we get a numeric 
result.

``` {r my-mean-2-NA}
my_mean2(c(1:5,NA), na.rm = TRUE)
```

A couple points worth noting about the functions above. First, take note that 
most *homemade* functions rely on other functions called within their body text, 
and so they inherit the properties of those functions.  
Second, you may have noticed that while 
the `body()` code in `my_mean2` assigns the mean of `x` to a new variable, `y`, 
this function-specific variable does not show up in the **"Global Environment"** 
pane after the function is executed. This is due to how *environments* are created
in R: an environment essentially draws walls around objects.  

Indeed, objects that are defined within functions are part of the *evaluation*
*environment* within that function, even if the function returns the value of 
the object as output (*"what happens inside functions stays inside functions"*). 
A detailed discussion on R environments is beyond the scope of this book, 
look [here](https://www.r-bloggers.com/environments-in-r/){target="_blank"}
for an introduction to environments and 
[here](https://adv-r.hadley.nz/environments.html){target="_blank"}
for a more detailed tutorial.
The take-home point is that a homemade function can exist within the global 
environment and return values to the global environment, even if the objects 
created within that function don't.

### Example Function: "import.w.name"
Oftentimes, you will have a list of files of the same type/structure
that you want to import and analyze in a single data frame. This exercise (and
the section that follows) will demonstrate how you can streamline that process
using functional programming. Let's create a function to *"import a file with* 
*its name appended".*

For this example, assume that your files represent data from network of sensors, 
where the ID assigned to each sensor is **included in its filename** but 
*not in the file itself*. To give you an example of what we are working with,
lets use `list.files()` to look at the file names and paths. For this exercise
we show a short list of 8 files (4 each from two sensors) but one could imagine
this list being hundreds of entries.*To Note: these are real data collected* 
*with using sensors from*  
*[this citizen-science network](http://www.purpleair.com/map){target="_blank"}*
*and published*
*by our research group*
*[here](https://doi.org/10.1016/j.atmosenv.2019.117067){target="_blank"} in 2019.*
The "PA" in each filename stands for 
[Purple Air](www.purpleair.com){target="_blank"}.

``` {r list-PA-files}
list.files('./data/purpleair/', full.names=TRUE)
```

Thus, we wish to write a function that not only imports these files into a data
frame but also extracts the part of the filename (i.e., PA019 and PA020) as one 
of the data columns (otherwise, when the data were, combined we might not know 
what data was associated with a given sensor!).  In this function we will also 
include a step to clean up the newly created data frame with a call to 
`dplyr::select()` to retain only a few variables of interest.  Seeing that these
files are .csv, we can leverage `readr::read_csv`

``` {r import-file-name, warning=FALSE, message=FALSE}
# create an object that tracks the file names and file paths
file_list <- list.files('./data/purpleair/', full.names=TRUE)

# function to import a .csv and include part of the filename as a data column
import.w.name <- function(pathname) {
  #create a tibble by importing the 'pathname' file
  df <- read_csv(pathname, col_names = TRUE)
  df <- df %>%
    # use stringr::str_extract & a regex to extract sensor ID from file name
    mutate(sensor_ID = str_extract(pathname, 
                                  "(?<=//)[:alnum:]+(?=_)")) %>%
    # clean up the resultant data frame with dplyr::select
    select(UTCDateTime, 
           current_temp_f, 
           current_humidity, 
           pressure,
           pm2_5_atm,
           sensor_ID)
  return(df)
}
```

After sourcing this function, we can test it out on the first entry of our list
of files.  *We specify the first entry with a subset to* `file_list[1]`.

``` {r import-file-name-2, message=FALSE, warning=FALSE}
PA_data_1 <- import.w.name(file_list[1])

head(PA_data_1)
```

The `import.w.name()` function is useful, but not versatile; 
it was written to handle a special type of file with a particular naming 
convention. Those limitations aside, one could imagine how this function could 
be easily adapted to suit other file types and formats.  As you develop your
coding skills, a good strategy is to keep useful functions in a .R script
file so that you can call upon them when needed: `source(import.w.name.R)`

## The `purrr::` package
The `purrr::` package was designed specifically with functional programming in mind.
Similar to the discussion of *vectorized operations* above, `purrr::` was created
to help you apply functions to vectors in a way that is easy to implement and 
easy to "read".

### Function Mapping
The `map_` family of functions are the core of the `purrr` package. These 
functions are intended to *map* functions (i.e., to apply them) to individual elements in a vector (or data frames); the `map_` functions are similar to functions like `lapply()` and `vapply()` from base R (but more versatile). *"Mapping"* a function onto a vector is a common theme of functional programming. To illustrate how the `map_` functions work, its best to visualize the process first.

``` {r map-anno1, fig.cap="The map functions transform their input by applying a function to each element of a list or atomic vector and returning an object of the same length as the input.", fig.align="center"}

knitr::include_graphics("./images/map_anno1.png")
```

As shown above in Figure \@ref(fig:map-anno1), the generic form of `map()`  always returns a `list` object as the output. Working with lists is one of the mental hurdles to overcome when learning `map()`. However, there are variants in the `map_` family of functions that return various object types.  

```{r purrr-variants}
purrr_variants <- tibble(
  name = c("map()",
           "map_lgl()", 
           "map_int()", 
           "map_dbl()", 
           "map_chr()", 
           "map_dfr()", 
           "map_dfc()"),
  returns = c("list",
              "logical",
              "integer",
              "numeric",
              "character",
              "data frame, by rows",
              "data frame, by columns")
)

knitr::kable(purrr_variants, col.names = c("`Purrr::` Function", "Object Returned"))

```


``` {r purrr-import, warning=FALSE, message=FALSE}
file_list <- list.files('./data/purpleair/', full.names=TRUE)
PA_data_merged <- map_df(file_list, import.w.name)

```

### Working with Lists

## Exercises



## Homework

Write a function that takes a vector of numbers as input and outputs that vector
sorted from smallest to largest value. Do this with only base R code and then 
with `dplyr::arrange()`. Hint: for the latter case you should look up the 
`require()` function.

Modify the function `import.w.name` to include two additional steps:  
  1. Convert the character vector `UTCDateTime` into a DateTime class object.
  2. Import the "date" part of the filename (in addition to the sensor ID) and 
  create a new column variable with this information.  Hint: provide regex pattern.
  
